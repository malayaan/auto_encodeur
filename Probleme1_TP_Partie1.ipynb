{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "##import data\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(train_images,_),(test_images,_)=mnist.load_data()\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##show an example of the images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test_images[0])\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##normalize all data set\n",
    "train_images = train_images.astype('float32')/255.\n",
    "test_images = test_images.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###reshape\n",
    "train_images = train_images.reshape(len(train_images),\n",
    "                                    np.prod(train_images.shape[1:]))\n",
    "test_images = test_images.reshape(len(test_images),\n",
    "                                  np.prod(test_images.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 784)               25872     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "encoding_dim = 32\n",
    "#the input layer with 784 features\n",
    "input_layer = Input(shape=(784,))\n",
    "#the hidden or encoded layer with 32 dimensions\n",
    "encoder_layer1 = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "#the decoded layer with 784 features\n",
    "decoder_layer1 = Dense(784, activation='sigmoid')(encoder_layer1)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_layer, decoder_layer1)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####testing to make the two seperately\n",
    "encoder = Model(input_layer,encoder_layer1)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input,decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compile autoencoder\n",
    "autoencoder.compile(optimizer='adam',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "235/235 [==============================] - 2s 5ms/step - loss: 0.2768 - val_loss: 0.1909\n",
      "Epoch 2/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1714 - val_loss: 0.1530\n",
      "Epoch 3/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1436 - val_loss: 0.1331\n",
      "Epoch 4/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1281 - val_loss: 0.1212\n",
      "Epoch 5/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1185 - val_loss: 0.1132\n",
      "Epoch 6/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1117 - val_loss: 0.1074\n",
      "Epoch 7/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1068 - val_loss: 0.1034\n",
      "Epoch 8/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1031 - val_loss: 0.1002\n",
      "Epoch 9/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1004 - val_loss: 0.0978\n",
      "Epoch 10/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0961\n",
      "Epoch 11/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0968 - val_loss: 0.0948\n",
      "Epoch 12/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0958 - val_loss: 0.0941\n",
      "Epoch 13/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0952 - val_loss: 0.0936\n",
      "Epoch 14/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0948 - val_loss: 0.0933\n",
      "Epoch 15/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 16/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 17/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0941 - val_loss: 0.0927\n",
      "Epoch 18/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 19/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 20/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0937 - val_loss: 0.0923\n",
      "Epoch 21/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0936 - val_loss: 0.0922\n",
      "Epoch 22/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 23/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 24/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 25/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 26/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 27/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 28/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 29/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 30/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 31/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 32/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 33/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 34/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0917\n",
      "Epoch 35/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 36/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 37/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0916\n",
      "Epoch 38/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 39/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 40/60\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 41/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 42/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 43/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 44/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 45/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 46/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 47/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 48/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 49/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 50/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 51/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 52/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 53/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 54/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 55/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 56/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 57/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 58/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 59/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 60/60\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0926 - val_loss: 0.0915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x152570a7950>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 60\n",
    "batch_size = 256\n",
    "\n",
    "autoencoder.fit(train_images,train_images,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_images,test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 905us/step\n",
      "(10000, 32)\n"
     ]
    }
   ],
   "source": [
    "encoded_imgs = encoder.predict(test_images)\n",
    "print(encoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "print(decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######plot the first 5\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n=5\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    #original images\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(test_images[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    #reconstructed images\n",
    "    ax = plt.subplot(2,n,i+1+n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.72682970e-11, 1.94203889e-11, 6.46115800e-11, ...,\n",
       "        3.59438659e-11, 1.82045756e-09, 7.03358899e-11],\n",
       "       [1.07608566e-11, 4.14218789e-12, 1.36633174e-12, ...,\n",
       "        2.35900470e-12, 4.47552802e-12, 5.81213409e-13],\n",
       "       [2.17208989e-08, 2.05524255e-08, 5.61755513e-08, ...,\n",
       "        5.43773666e-08, 5.05765385e-08, 9.62756719e-09],\n",
       "       ...,\n",
       "       [9.28645631e-16, 6.41651556e-15, 1.06664928e-14, ...,\n",
       "        1.03075598e-15, 4.28022147e-14, 2.89421396e-15],\n",
       "       [9.27526082e-14, 1.18201727e-12, 6.81961269e-13, ...,\n",
       "        9.69022063e-13, 2.25135557e-12, 1.74344561e-13],\n",
       "       [1.20324915e-20, 6.39760679e-20, 7.53184550e-19, ...,\n",
       "        1.82045691e-21, 5.13699484e-20, 1.70290255e-21]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.predict(test_images,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partie 8:\n",
    "\n",
    "en suivant les consignes de la question, nous allons:\n",
    "\n",
    "Parcourir chaque combinaison d'optimiseur et de fonction de perte.\n",
    "Réinitialiser et compiler l'autoencodeur avec chaque combinaison.\n",
    "Entraîner le modèle sur les données d'entraînement.\n",
    "Prédire sur les données de test et calculer l'erreur quadratique moyenne (MSE).\n",
    "Stocker et trier les résultats en fonction de la MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 3s 6ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0913\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0915\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0913\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0914\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0925 - val_loss: 0.0913\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 4s 15ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0924 - val_loss: 0.0914\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 3s 15ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0923 - val_loss: 0.0913\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0923 - val_loss: 0.0912\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0921 - val_loss: 0.0910\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0920 - val_loss: 0.0910\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0910\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 3s 14ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 4s 17ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0919 - val_loss: 0.0909\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 4s 11ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 3s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 3s 11ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Optimiseur: sgd, Perte: mean_squared_error - MSE: 0.009268435649573803\n",
      "Optimiseur: adam, Perte: mean_squared_error - MSE: 0.009357059374451637\n",
      "Optimiseur: sgd, Perte: binary_crossentropy - MSE: 0.009424368850886822\n",
      "Optimiseur: adam, Perte: binary_crossentropy - MSE: 0.009505060501396656\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Définition des combinaisons d'optimiseurs et de fonctions de perte\n",
    "combinations = [\n",
    "    ('adam', 'binary_crossentropy'),\n",
    "    ('sgd', 'binary_crossentropy'),\n",
    "    ('adam', 'mean_squared_error'),\n",
    "    ('sgd', 'mean_squared_error')\n",
    "]\n",
    "\n",
    "# Espace pour stocker les résultats\n",
    "results = []\n",
    "\n",
    "for optimizer, loss_function in combinations:\n",
    "    # Réinitialiser le modèle avec la même architecture\n",
    "    autoencoder = Model(input_layer, decoder_layer1)\n",
    "    \n",
    "    # Compiler le modèle avec le nouvel optimiseur et la nouvelle fonction de perte\n",
    "    autoencoder.compile(optimizer=optimizer, loss=loss_function)\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    autoencoder.fit(train_images, train_images,\n",
    "                    epochs=50,\n",
    "                    batch_size=256,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_images, test_images))\n",
    "\n",
    "    # Prédire sur les données de test\n",
    "    decoded_images = autoencoder.predict(test_images)\n",
    "\n",
    "    # Calculer la MSE (erreur quadratique moyenne)\n",
    "    mse = np.mean(mean_squared_error(test_images, decoded_images))\n",
    "\n",
    "    # Stocker les résultats\n",
    "    results.append((f'Optimiseur: {optimizer}, Perte: {loss_function}', mse))\n",
    "\n",
    "# Trier les résultats par mse\n",
    "results.sort(key=lambda x: x[1])\n",
    "\n",
    "# Afficher les résultats\n",
    "for combination, mse in results:\n",
    "    print(f'{combination} - MSE: {mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La meilleure performance est obtenue avec l'optimiseur SGD et la fonction de perte `mean_squared_error`, indiquant une légère supériorité dans la reconstruction des images. Les optimiseurs Adam et SGD montrent des performances comparables, soulignant leur efficacité. La fonction de perte `mean_squared_error` s'avère légèrement plus performante, probablement car elle est directement liée à la minimisation de l'erreur de reconstruction, ce qui est crucial pour les autoencodeurs. Les différences minimes entre les combinaisons suggèrent que le modèle d'autoencodeur est relativement robuste aux variations de ces paramètres pour le dataset MNIST. La simplicité de la base de données exploité justifie la proximité des résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant entraîner l'autoencodeur avec différentes combinaisons d'époques et de taille de lot, puis calculer et afficher la MSE pour chaque combinaison. Vous pourrez ainsi identifier la combinaison optimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 1s 7ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 3s 6ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "313/313 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "120/120 [==============================] - 2s 12ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.0095 - val_loss: 0.0093\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Epochs, Batch Size - MSE\n",
      "(10, 100) - 0.009259224869310856\n",
      "(10, 500) - 0.009259144775569439\n",
      "(50, 100) - 0.009257618337869644\n",
      "(50, 500) - 0.009257389232516289\n"
     ]
    }
   ],
   "source": [
    "combinations = [\n",
    "    (10, 100),  # 10 epochs, 128 batch_size\n",
    "    (10, 500),  # 10 epochs, 256 batch_size\n",
    "    (50, 100),  # 50 epochs, 128 batch_size\n",
    "    (50, 500)   # 50 epochs, 256 batch_size\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for epochs, batch_size in combinations:\n",
    "    # Reinitialiser et compiler l'autoencodeur\n",
    "    autoencoder.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "    # Entraîner le modèle avec les nouvelles valeurs\n",
    "    autoencoder.fit(train_images, train_images,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(test_images, test_images))\n",
    "\n",
    "    # Calculer la MSE sur les données de test\n",
    "    decoded_images = autoencoder.predict(test_images)\n",
    "    mse = np.mean(mean_squared_error(test_images, decoded_images))\n",
    "\n",
    "    # Ajouter les résultats\n",
    "    results.append(((epochs, batch_size), mse))\n",
    "\n",
    "# Afficher les résultats sous forme de tableau\n",
    "print(\"Epochs, Batch Size - MSE\")\n",
    "for comb, mse in results:\n",
    "    print(f\"{comb} - {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats montrent des MSE très similaires pour toutes les combinaisons d'époques et de tailles de lot, indiquant une influence minime de ces paramètres sur la performance de l'autoencodeur dans ce cas. Cependant, la combinaison (50 époques, 500 en taille de lot) donne la MSE la plus faible, suggérant une amélioration marginale en augmentant à la fois le nombre d'époques et la taille de lot. Cela peut indiquer que l'autoencodeur bénéficie d'un entraînement plus long et de lots plus importants pour affiner légèrement ses performances. Néanmoins, étant donné la faible différence entre les combinaisons, le choix spécifique d'époques et de taille de lot semble avoir un impact limité dans ce contexte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir des résultats plus significatifs, on pourrait essayer :\n",
    "\n",
    "1. **Elargir la Gamme des Paramètres** : Tester des époques et des tailles de lot plus variées.\n",
    "2. **Optimisation Hyperparamétrique** : Utiliser des techniques comme Grid Search ou Random Search.\n",
    "3. **Modifier l'Architecture du Modèle** : Expérimenter avec différentes architectures de l'autoencodeur.\n",
    "4. **Utiliser un Dataset Plus Complex** : Essayer avec des ensembles de données plus exigeants que MNIST.\n",
    "5. **Analyser d'Autres Métriques** : Considérer d'autres mesures de performance en plus de la MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 784)               25872     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 2s 11ms/step - loss: 0.3387 - val_loss: 0.2297\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.2031 - val_loss: 0.1830\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 1s 9ms/step - loss: 0.1737 - val_loss: 0.1626\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1561 - val_loss: 0.1475\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1432 - val_loss: 0.1365\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1337 - val_loss: 0.1283\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1264 - val_loss: 0.1218\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1206 - val_loss: 0.1165\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1157 - val_loss: 0.1121\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1117 - val_loss: 0.1084\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1083 - val_loss: 0.1055\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 1s 10ms/step - loss: 0.1055 - val_loss: 0.1029\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.1033 - val_loss: 0.1009\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.1014 - val_loss: 0.0993\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0999 - val_loss: 0.0979\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0986 - val_loss: 0.0968\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0976 - val_loss: 0.0958\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0968 - val_loss: 0.0952\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0961 - val_loss: 0.0945\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0956 - val_loss: 0.0941\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0952 - val_loss: 0.0937\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0948 - val_loss: 0.0934\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0946 - val_loss: 0.0932\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0944 - val_loss: 0.0930\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0940 - val_loss: 0.0928\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 1s 12ms/step - loss: 0.0937 - val_loss: 0.0925\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0933 - val_loss: 0.0922\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 1s 11ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "313/313 [==============================] - 0s 912us/step\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding_dim = 32\n",
    "#the input layer with 784 features\n",
    "input_layer = Input(shape=(784,))\n",
    "#the hidden or encoded layer with 32 dimensions\n",
    "encoder_layer1 = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "#the decoded layer with 784 features\n",
    "decoder_layer1 = Dense(784, activation='sigmoid')(encoder_layer1)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_layer, decoder_layer1)\n",
    "autoencoder.summary()\n",
    "####testing to make the two seperately\n",
    "encoder = Model(input_layer,encoder_layer1)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input,decoder_layer(encoded_input))\n",
    "\n",
    "#### Compile autoencoder\n",
    "autoencoder.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "# Entraînement de l'autoencodeur avec les paramètres optimaux\n",
    "autoencoder.fit(train_images, train_images, epochs=50, batch_size=500, shuffle=True, validation_data=(test_images, test_images))\n",
    "\n",
    "# Prédiction et visualisation des images\n",
    "encoded_imgs = encoder.predict(test_images)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# Affichage des images originales et reconstruites\n",
    "n = 5\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Images originales\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(test_images[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Images reconstruites\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats semblent sensibelemnt mieux (comme le 4 ou le 1) mais dans l'ensemble ils étaient déjà bons. le set est surement trop simple pour qu'on voit la difference. \n",
    "Voici les anciens pour la comparaison:"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
